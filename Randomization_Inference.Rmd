---
title: "241 Randomization Inference"
author: "Monica Napoles"
date: "2024-11-20"
output: pdf_document
---

```{r setup, include=FALSE}
library(dplyr)
library(ggplot2)

```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

donations <- read.csv("/Users/monicanapoles/241-Final-Project/data/alk_donations_total_ex_fee.csv", stringsAsFactors = FALSE)

#Filter undelivered emails 
donations <- donations %>% filter(email_undelivered != 1)

donations

#quick check on emails opened
df_email_counts <- donations %>%
  group_by(test_name, email_opened) %>%
  summarize(n = n())

print(df_email_counts)

```

```{r}
#keep only donations 
#donations_filtered <- donations %>% filter(!is.na(donation_amount_ex_fee))

#donations_filtered
```

```{r}
#calculate the ATE

observed_ate <- (3/19) - (0/17)

observed_ate

```

```{r}
#assign binary to treatment and control 
#calculate poportions of exact matches
proportions <- donations %>%
  filter(email_opened == 1) %>%
  mutate(exact_match = ifelse((test_name == "Test B" & donation_amount_ex_fee == 13) |
                              (test_name == "Test A" & donation_amount_ex_fee == 10), 1, 0)) %>%
  group_by(test_name) %>%
  summarise(proportion_exact = mean(exact_match))

#proportions

# number of people who actually opened the email in each group (received treatment and received control)
group_sizes <- list("Test A" = 17, "Test B" = 19)
```


```{r}
simulate_exact_matches <- function(simulations = 1000, group_sizes) {
  sim_results <- data.frame(Test_A = numeric(simulations), Test_B = numeric(simulations))
  
  for (sim in 1:simulations) {
    # Test A
    sim_results$Test_A[sim] <- mean(runif(group_sizes[["Test A"]]) < proportions$proportion_exact[1])
    
    # Test B
    sim_results$Test_B[sim] <- mean(runif(group_sizes[["Test B"]]) < proportions$proportion_exact[2])
  }
  
  sim_results <- sim_results %>%
    mutate(Test_Effect = Test_B - Test_A)
  
  return(sim_results)
}

```

```{r}
set.seed(42)

# Simulate
n_simulations <- 100000
simulated_results <- simulate_exact_matches(n_simulations, group_sizes)

observed_test_effect <- 
  proportions$proportion_exact[1] - proportions$proportion_exact[2]


p_value <- mean(abs(simulated_results$Test_Effect) >= abs(observed_test_effect))
p_value
```
```{r}

ggplot(simulated_results, aes(x = Test_Effect)) +
  geom_histogram(bins = 10, fill = "lightblue", color = "black", alpha = 0.9) +
  geom_vline(xintercept = observed_ate, color = "red", linetype = "dashed", size = 1) +
  labs(
    title = "Simulated Test Effects vs. Observed Effect",
    x = "Test Effect (Proportion Difference)",
    y = "Frequency"
  ) +
  theme_minimal()

```

The graph suggests no strong evidence to support a difference between the two groups which is in line with the simulated p-value. 



The null hypothesis: there is no difference in the proportion of people who matched the suggested donation between the two groups. When calculating the proportions for the randomization inference, we are only consider the individuals who opened the email because we are interested in the effect of the treatment (suggested donation amount) on those who were exposed to it. With a p-value of 0.59617, we fail to reject the null of no difference in the proportion of people who matched the suggested donation between the two groups. 

```{r}
sd_simulated_test_effect <- sd(simulated_results$Test_Effect)

# Print the standard deviation
print(sd_simulated_test_effect)
```


